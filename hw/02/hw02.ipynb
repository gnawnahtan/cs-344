{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a265e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f6a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_types = 'gamma', 'theta'\n",
    "path = Path('/home/nw37/Desktop/SP22/CS344/hw/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9aa9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#74) [Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_26.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_03.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_14.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_30.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_29.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_08.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_12.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_18.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_02.jpg'),Path('/home/nw37/Desktop/SP22/CS344/hw/02/gamma/Gamma_31.jpg')...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = get_image_files(path)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b9f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for question 3, try with fewer images\n",
    "images_2 = []\n",
    "for x in range(20):\n",
    "    images_2.append(images[random.randrange(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efcc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct data loader\n",
    "# first seed = 34521\n",
    "# second seed = 78912\n",
    "# third seed = 12345\n",
    "set_seed(12345, reproducible=True)\n",
    "dataloaders = ImageDataLoaders.from_path_func(\n",
    "    path=path,\n",
    "    fnames=images_2,\n",
    "    valid_pct=0.2,\n",
    "    seed=42,\n",
    "    label_func=parent_label,\n",
    "    item_tfms=Resize(224),\n",
    "    bs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2a71be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.636559</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.761938</td>\n",
       "      <td>0.872673</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = cnn_learner(\n",
    "    dls=dataloaders,\n",
    "    arch=resnet34,\n",
    "    metrics=error_rate\n",
    ")\n",
    "learn.fine_tune(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1_error_rates = [0.0, 0.0, 0,0]\n",
    "clf_2_error_rates = [0.5, 0.0,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix time\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150e465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bbc5a5",
   "metadata": {},
   "source": [
    "- How accurate is your classifier? Report your answer as a range (lower to upper) of expected accuracy values.\n",
    "  - Apparently very accurate, with error rates of `0`. In this case, 0 to 0. \n",
    "- What sort of mistakes did it make? Why do you think it may have made those mistakes?\n",
    "  - Surprisingly, it didn't make any. I think this is because the images are too similar. For context, my buddy told me he took burst photos; therefore, the images only differed insignificantly.\n",
    "- How many images do you need to get good accuracy? (Try your classifier on fewer images.)\n",
    "  - This is difficult to answer because the images aren't great. It does seem like the original number of photos (74) produced more accurate results than when I removed 20.\n",
    "- What choices did you have to make in the process of collecting data, processing it, and analyzing the results?\n",
    "  - When collecting data, the photos were taken burst style to quicken the collection process. When processing the data, I changed all the image sizes to the same resolution. When analyzing them, I changed the random seed.\n",
    "- What are one or two choices that you could have made differently?\n",
    "  - I could have taken the photos myself by teleporting there. In all seriousness, I could have requested the photos to be taken from different angles. Another choice I have is that I could have requested more to be taken. \n",
    "- What do you expect would be different if you made that different choice?\n",
    "  - I would expect the error rate to be higher because the images wouldn't be as similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae261c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
